ğŸ™ï¸ PIPER TTS TRAINING PROCESS FLOW
=====================================

ğŸ“ STEP 1: RECORDING
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User reads sentences â†’ Browser records audio â†’ Save to disk â”‚
â”‚                                                             â”‚
â”‚  Files created:                                             â”‚
â”‚  voices/{profile}/recordings/0001_sv-SE_Chat_20251011.wav  â”‚
â”‚  voices/{profile}/metadata.jsonl                           â”‚
â”‚  voices/{profile}/progress.json                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
ğŸ§¼ STEP 2: POST-PROCESSING
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Clean audio â†’ Normalize volume â†’ Trim silence â†’ Add padding â”‚
â”‚                                                             â”‚
â”‚  Files modified:                                            â”‚
â”‚  voices/{profile}/recordings/*.wav (processed)             â”‚
â”‚  voices/{profile}/backups/*.wav.backup (originals)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
ğŸ“¤ STEP 3: EXPORT
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Convert format â†’ Export with metadata â†’ Create ZIP archive â”‚
â”‚                                                             â”‚
â”‚  Files created:                                             â”‚
â”‚  exports/{profile}_{list}_{timestamp}/                     â”‚
â”‚  â”œâ”€â”€ audio/*.wav, *.mp3, *.flac, *.ogg                    â”‚
â”‚  â”œâ”€â”€ metadata.json                                         â”‚
â”‚  â”œâ”€â”€ transcripts.txt                                       â”‚
â”‚  â””â”€â”€ dataset.zip                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
ğŸ§  STEP 4: TRAINING
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prepare dataset â†’ Convert phonemes â†’ Align audio â†’ Train   â”‚
â”‚                                                             â”‚
â”‚  Files created:                                             â”‚
â”‚  training_output/{model_name}/                             â”‚
â”‚  â”œâ”€â”€ dataset/audio/, phonemes/, alignment/                 â”‚
â”‚  â”œâ”€â”€ checkpoints/epoch_*.ckpt                              â”‚
â”‚  â”œâ”€â”€ logs/training.log                                     â”‚
â”‚  â””â”€â”€ final_model/model.ckpt, config.json, onnx_model.onnx â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
ğŸ—£ï¸ STEP 5: SYNTHESIS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Load model â†’ Convert text â†’ Generate speech â†’ Output audio â”‚
â”‚                                                             â”‚
â”‚  Files created:                                             â”‚
â”‚  synthesis_output/generated_audio.wav                      â”‚
â”‚  synthesis_output/phonemes.txt                             â”‚
â”‚  synthesis_output/timing.json                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”§ TECHNICAL COMPONENTS
=======================

Frontend (Web Interface):
â”œâ”€â”€ /templates/record.html      â†’ Recording interface
â”œâ”€â”€ /templates/postprocess.html â†’ Post-processing interface
â”œâ”€â”€ /templates/export.html      â†’ Export interface
â”œâ”€â”€ /templates/train.html       â†’ Training interface
â””â”€â”€ /static/js/recorder.js      â†’ Audio recording logic

Backend (API & Processing):
â”œâ”€â”€ app.py                      â†’ Main FastAPI application
â”œâ”€â”€ train_model.py              â†’ Training script
â””â”€â”€ utils/
    â”œâ”€â”€ audio.py               â†’ Audio processing utilities
    â”œâ”€â”€ phonemes.py            â†’ Phoneme conversion system
    â”œâ”€â”€ mfa.py                 â†’ Montreal Forced Aligner
    â””â”€â”€ checkpoints.py         â†’ Pre-trained model management

Data Storage:
â”œâ”€â”€ voices/                    â†’ User recordings
â”œâ”€â”€ exports/                   â†’ Exported datasets
â”œâ”€â”€ training_output/           â†’ Training results
â””â”€â”€ checkpoints/               â†’ Pre-trained models

ğŸ¯ KEY PROCESSES
================

1. RECORDING:
   - User reads prompts from web interface
   - Browser captures audio via MediaRecorder API
   - Audio saved as WAV files with metadata
   - Progress tracked in JSON files

2. POST-PROCESSING:
   - Audio normalized to consistent volume
   - Silence trimmed from start/end
   - Consistent padding added
   - Original files backed up

3. EXPORT:
   - Audio converted to various formats
   - Metadata and transcripts included
   - ZIP archives created for distribution
   - Multiple quality options available

4. TRAINING:
   - Text converted to phonemes using eSpeak NG
   - Audio aligned with phonemes using MFA
   - Model trained with PyTorch/Piper
   - Checkpoints saved at intervals

5. SYNTHESIS:
   - Trained model loads phoneme sequences
   - Neural network generates audio
   - Output saved as WAV files
   - Ready for use in applications

ğŸš€ GETTING STARTED
==================

1. Start the app: python app.py
2. Go to: http://localhost:8000
3. Create voice profile
4. Record sentences
5. Post-process audio
6. Export dataset
7. Train model
8. Generate speech!

The complete pipeline is now automated and user-friendly! ğŸ‰
